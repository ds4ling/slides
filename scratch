
---
layout: false
class: title-slide-section-grey, middle

# Interactions

---
layout: true

# Interactions

---

#### Recall

.pull-left[

- Assumptions of Multiple Regression: 
  - Additivity
  - Linearity
- In Boolean Algebra, a sum (addition) represents a logical disjunction: 
  - Multiple regression "weighted sum" is a complex "OR" statement

]

.pull-right[

| A</br>(x) | B</br>(y) | C</br>(x **∨** y) |
| :-------: | :-------: | :---------------: |
| 0         | 0         |   **0**           | 
| 0         | 1         |   **1**           |
| 1         | 0         |   **1**           |
| 1         | 1         |   **1**           |

.center[

If A = 1  
**OR**  
B = 1,  
then C = 1  
Otherwise, C = 0

]
]

---

#### Recall

.pull-left[

- Assumptions of Multiple Regression: 
  - Additivity
  - Linearity
- In Boolean Algebra, a sum (addition) represents a logical .blue[disjunction]: 
  - Multiple regression "weighted sum" is a complex "OR" statement

#### Non-Additivity: Interaction Terms

- In Boolean Algebra, a product (multiplication) represents a logical 
**conjunction**:
  - Interaction terms represent "AND" terms
  - These are included within the overall "OR" statement

]

.pull-right[

| A</br>(x) | B</br>(y) | C</br>(x **∧** y) | </br>.grey[(x ∨ y)] |
| :-------: | :-------: | :---------------: | :-----------------: |
| 0         | 0         |   **0**           |   .lightgrey[0]     |
| 0         | 1         |   **0**           |   .lightgrey[1]     |
| 1         | 0         |   **0**           |   .lightgrey[1]     |
| 1         | 1         |   **1**           |   .lightgrey[1]     |

.center[

If A = 1  
**AND**  
B = 1,  
then C = 1  
Otherwise, C = 0

]
]

---

.pull-left[

### Genetics example

- You share 50% of genes with your Mom (M) and 50% with your Dad (D)

- But your parents don’t share that many genes

- M and D are generally not genetically correlated with each other, but you 
(the M\*D interaction) are correlated with both M and D (more on this later)

]

--

.pull-right[

### Drugs and alcohol

Consider taking the upcoming midterm in one of the following conditions

- Neither Drugs nor Alcohol:
  - probably best, produce highest score
- Alcohol alone:
  - Probably lower midterm scores than doing neither
- Drugs alone:
  - Probably lower midterm scores than doing neither
- Alcohol and Drugs together:
  - Probably lowest scores on the midterm exam of 
    all the four possible conditions

]

---

### Drugs and alcohol continued

<p></p>

.large[
- Is the effect of alcohol and drugs together equal to the negative effect 
of alcohol PLUS the negative effect of drugs?
  - Probably not
  - Alcohol and drugs are known to interact 
]

<p></p>

.large[
- This effect is a negative interaction
]

<p></p>

.large[
- If you mix alcohol and drugs they have a larger combined effect than 
adding up the effects of each acting separately:
  - For example, if alcohol makes your score drop 10 points, and the drug 
  drops it 15 points, when you take both your score will very likely drop 
  more than just 25 points
]

<p></p>

.large[
- This effect is not additive, it is multiplicative
]

---

### Non-additivity of effects

.Large[
- You cannot add the effect of alcohol to the effect of drugs to predict the effect "alcohol AND drugs"

- Because you get an extra effect (a boosting effect) by combing them

- There is a synergistic effect of combining the terms

- In principle, could be either more or less effective

- You include this multiplicative **AND** term (A\*D) in *ADDITION* to the other terms in the model
]

---

.pull-left[

### The multiple regression formula: 

$$Y = a_{0} + b_{1}X_{1} + b_{2}X_{2} + (b_{1}X_{1} \times b_{2}X_{2}) + e$$

### Including interactions in R

- We do this using `:`

- Or \*

]

--

.pull-right[

```{r}
#| label: nonadditive_mod
#| comment: ""
m <- lm(mpg ~ wt + drat + wt:drat, data = mtcars) #<<
summary(m)
```

]

---

### Visualization

.Large[
- Including an interaction affects the hyperplane fit to the data
]

---
background-color: black

```{r}
#| label: additive_interaction
# compare additive and int models
par(bg = 'black')
plot3D::scatter3D(x, y, z, 
  pch = 1, cex = 0, bty = "bl", expand = 0.75,
  theta = 50, phi = 10,  colkey = F, tick.col = 'white', 
  xlab = "wt", ylab = "drat", zlab = "mpg", 
  surf = list(x = x_pred, y = y_pred, z = z_pred_add,  
              facets = NA))

plot3D::scatter3D(x, y, z, 
  pch = 1, cex = 0, bty = "bl", expand = 0.75,
  theta = 50, phi = 10,  colkey = F,
  xlab = "wt", ylab = "drat", zlab = "mpg", 
  surf = list(x = x_pred, y = y_pred, z = z_pred_int,  
              facets = NA))
```

---

```{r}
#| label: additive_interaction2

# compare additive and int models
#par(bg = 'black')
plot3D::scatter3D(x, y, z, 
  pch = 1, cex = 0, bty = "bl", expand = 0.75,
  theta = 50, phi = 10,  colkey = F,
  xlab = "wt", ylab = "drat", zlab = "mpg", 
  surf = list(x = x_pred, y = y_pred, z = z_pred_add,  
              facets = NA))

plot3D::scatter3D(x, y, z, 
  pch = 1, cex = 0, bty = "bl", expand = 0.75,
  theta = 50, phi = 10,  colkey = F,
  xlab = "wt", ylab = "drat", zlab = "mpg", 
  surf = list(x = x_pred, y = y_pred, z = z_pred_int,  
              facets = NA))
```

---
background-color: black

```{r}
#| label: additive_interaction3

# compare additive and int models
par(bg = 'black')
plot3D::scatter3D(x, y, z, 
  pch = 1, cex = 0, bty = "bl", expand = 0.75,
  theta = 0, phi = 5,  colkey = F,
  xlab = "wt", ylab = "drat", zlab = "mpg", 
  surf = list(x = x_pred, y = y_pred, z = z_pred_int,  
              facets = NA))

plot3D::scatter3D(x, y, z, 
  pch = 1, cex = 0, bty = "bl", expand = 0.75,
  theta = 90, phi = 5,  colkey = F,
  xlab = "wt", ylab = "drat", zlab = "mpg", 
  surf = list(x = x_pred, y = y_pred, z = z_pred_int,  
              facets = NA))
```

---

```{r}
#| label: additive_interaction4

# compare additive and int models
plot3D::scatter3D(x, y, z, 
  pch = 1, cex = 0, bty = "bl", expand = 0.75,
  theta = 0, phi = 5,  colkey = F,
  xlab = "wt", ylab = "drat", zlab = "mpg", 
  surf = list(x = x_pred, y = y_pred, z = z_pred_int,  
              facets = NA))

plot3D::scatter3D(x, y, z, 
  pch = 1, cex = 0, bty = "bl", expand = 0.75,
  theta = 90, phi = 5,  colkey = F,
  xlab = "wt", ylab = "drat", zlab = "mpg", 
  surf = list(x = x_pred, y = y_pred, z = z_pred_int,  
              facets = NA))
```

---
layout: false
class: title-slide-section-red

# Review

### What we've seen so far

.Large[
- Bivariate regression
- MRC
- Additive effects
- Interactions (multiplicative effects)
]

### What's left

.Large[
- Assumptions
- Model specification
- Alpha slippage
- Empirical selection of variables
- Reporting results
]





















# {.transition visibility="uncounted"}

{{< tweet user=merm_bot id=1841652233651233066 >}}
<!-- another day coding in R --> 


<!-- https://www.react-graph-gallery.com/example/t-test-playground --> 

---

## {.smaller}

```{ojs}
// Import Observable Plot
import { Plot } from "@observablehq/plot";

// Create sliders for slope and intercept
viewof slope = Inputs.range([-5, 5], { 
  value: 1, 
  step: 0.1, 
  label: "Slope", 
  width: 250
});

viewof intercept = Inputs.range([-2, 2], { 
  value: 0, 
  step: 0.1, 
  label: "Intercept", 
  width: 250
});

// Stack sliders vertically
html`<div style="display: flex; flex-direction: column; gap: 20px; align-items: center;">
  <div>${viewof slope}</div>
  <div>${viewof intercept}</div>
</div>`;

// Generate a random dataset with 100 points
randomDataRaw = Array.from({ length: 100 }, () => {
  let x = Math.random() * 10;  // Random x values between 0 and 10
  let noise = (Math.random() - 0.5) * 2;  // Small noise for realism
  let y = x + noise;  // True relationship: y = x + noise
  return { x, y };
});

// Compute mean and standard deviation
meanX = randomDataRaw.reduce((sum, d) => sum + d.x, 0) / randomDataRaw.length;
meanY = randomDataRaw.reduce((sum, d) => sum + d.y, 0) / randomDataRaw.length;

stdX = Math.sqrt(randomDataRaw.reduce((sum, d) => sum + (d.x - meanX) ** 2, 0) / randomDataRaw.length);
stdY = Math.sqrt(randomDataRaw.reduce((sum, d) => sum + (d.y - meanY) ** 2, 0) / randomDataRaw.length);

// Standardize the data
fixedData = randomDataRaw.map(d => ({
  x: (d.x - meanX) / stdX,  // Standardized X
  y: (d.y - meanY) / stdY   // Standardized Y
}));

// Regression line updates dynamically, but data remains fixed
regressionLine = [
  { x: -2, y: slope * -2 + intercept },  // Line starts at x=-2
  { x: 2, y: slope * 2 + intercept }  // Line ends at x=2
]

// Create the scatterplot with fixed axes
Plot.plot({
  width: window.innerWidth,  // Full-width plot
  height: 750,
  marginLeft: 50,
  x: { 
    label: { text: "Standardized X", fontSize: 22 },  // Increase font size for x axis labels
    domain: [-2, 2],  // Fixed X-axis range
    tickFormat: (d) => d.toFixed(1)
  },
  y: { 
    label: { text: "Standardized Y", fontSize: 22 },  // Increase font size for y axis labels
    domain: [-2, 2],  // Fixed Y-axis range
    tickFormat: (d) => d.toFixed(1)
  },
  marks: [
    Plot.dot(fixedData, { x: "x", y: "y", fill: "steelblue", r: 3 }),  // Fixed scatter points
    Plot.line(regressionLine, { x: "x", y: "y", stroke: "red", strokeWidth: 2 })  // Regression line
  ]
})
```
